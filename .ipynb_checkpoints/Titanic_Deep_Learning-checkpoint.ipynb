{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.metrics import categorical_accuracy as accuracy\n",
    "from keras import regularizers\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = pd.read_csv('train.csv')\n",
    "features_test = pd.read_csv('test.csv')\n",
    "labels_train = features_train['Survived']\n",
    "features_train.drop('Survived', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_features = features_train.append(features_test)\n",
    "combined_features.reset_index(inplace=True)\n",
    "combined_features.drop('index', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_features['Title']= combined_features['Name'].map(\n",
    "    lambda name: name.split(',')[1].split('.')[0].strip())\n",
    "Title_Dictionary = {\n",
    "                        \"Capt\":       \"Officer\",\n",
    "                        \"Col\":        \"Officer\",\n",
    "                        \"Major\":      \"Officer\",\n",
    "                        \"Jonkheer\":   \"Royalty\",\n",
    "                        \"Don\":        \"Royalty\",\n",
    "                        \"Sir\" :       \"Royalty\",\n",
    "                        \"Dr\":         \"Officer\",\n",
    "                        \"Rev\":        \"Officer\",\n",
    "                        \"the Countess\":\"Royalty\",\n",
    "                        \"Dona\":       \"Royalty\",\n",
    "                        \"Mme\":        \"Mrs\",\n",
    "                        \"Mlle\":       \"Miss\",\n",
    "                        \"Ms\":         \"Mrs\",\n",
    "                        \"Mr\" :        \"Mr\",\n",
    "                        \"Mrs\" :       \"Mrs\",\n",
    "                        \"Miss\" :      \"Miss\",\n",
    "                        \"Master\" :    \"Master\",\n",
    "                        \"Lady\" :      \"Royalty\"\n",
    "\n",
    "                        }\n",
    "combined_features['Title']=combined_features.Title.map(Title_Dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing the ages\n",
    "grouped_train = combined_features.head(891).groupby(['Sex','Pclass','Title'])\n",
    "grouped_median_train = grouped_train.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/generic.py:5096: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "grouped_test = combined_features.iloc[891:].groupby(['Sex','Pclass','Title'])\n",
    "grouped_median_test = grouped_test.median()\n",
    "def fillAges(row, grouped_median):\n",
    "    if row['Sex'] == 'female' and row['Pclass'] == 1:\n",
    "        if row['Title'] == 'Miss':\n",
    "            return grouped_median.loc['female', 1, 'Miss']['Age']\n",
    "        elif row['Title'] == 'Mrs':\n",
    "            return grouped_median.loc['female', 1, 'Mrs']['Age']\n",
    "        elif row['Title'] == 'Officer':\n",
    "            return grouped_median.loc['female', 1, 'Officer']['Age']\n",
    "        elif row['Title'] == 'Royalty':\n",
    "            return grouped_median.loc['female', 1, 'Royalty']['Age']\n",
    "\n",
    "    elif row['Sex'] == 'female' and row['Pclass'] == 2:\n",
    "        if row['Title'] == 'Miss':\n",
    "            return grouped_median.loc['female', 2, 'Miss']['Age']\n",
    "        elif row['Title'] == 'Mrs':\n",
    "            return grouped_median.loc['female', 2, 'Mrs']['Age']\n",
    "\n",
    "    elif row['Sex'] == 'female' and row['Pclass'] == 3:\n",
    "        if row['Title'] == 'Miss':\n",
    "            return grouped_median.loc['female', 3, 'Miss']['Age']\n",
    "        elif row['Title'] == 'Mrs':\n",
    "            return grouped_median.loc['female', 3, 'Mrs']['Age']\n",
    "\n",
    "    elif row['Sex'] == 'male' and row['Pclass'] == 1:\n",
    "        if row['Title'] == 'Master':\n",
    "            return grouped_median.loc['male', 1, 'Master']['Age']\n",
    "        elif row['Title'] == 'Mr':\n",
    "            return grouped_median.loc['male', 1, 'Mr']['Age']\n",
    "        elif row['Title'] == 'Officer':\n",
    "            return grouped_median.loc['male', 1, 'Officer']['Age']\n",
    "        elif row['Title'] == 'Royalty':\n",
    "            return grouped_median.loc['male', 1, 'Royalty']['Age']\n",
    "\n",
    "    elif row['Sex'] == 'male' and row['Pclass'] == 2:\n",
    "        if row['Title'] == 'Master':\n",
    "            return grouped_median.loc['male', 2, 'Master']['Age']\n",
    "        elif row['Title'] == 'Mr':\n",
    "            return grouped_median.loc['male', 2, 'Mr']['Age']\n",
    "        elif row['Title'] == 'Officer':\n",
    "            return grouped_median.loc['male', 2, 'Officer']['Age']\n",
    "\n",
    "    elif row['Sex'] == 'male' and row['Pclass'] == 3:\n",
    "        if row['Title'] == 'Master':\n",
    "            return grouped_median.loc['male', 3, 'Master']['Age']\n",
    "        elif row['Title'] == 'Mr':\n",
    "            return grouped_median.loc['male', 3, 'Mr']['Age']\n",
    "\n",
    "combined_features.head(891).Age = combined_features.head(891).apply(lambda r: fillAges(r, grouped_median_train) if np.isnan(r['Age'])\n",
    "    else r['Age'], axis=1)\n",
    "\n",
    "combined_features.iloc[891:].Age = combined_features.iloc[891:].apply(lambda r: fillAges(r, grouped_median_test) if np.isnan(r['Age'])\n",
    "    else r['Age'], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing names: drop names and encode the titles using dummy encoding from pandas\n",
    "combined_features.drop('Name', axis=1, inplace=True)\n",
    "dummy_titles = pd.get_dummies(combined_features['Title'], prefix='Title')\n",
    "combined_features = pd.concat([combined_features, dummy_titles], axis=1)\n",
    "combined_features.drop('Title', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/generic.py:6130: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "# Processing Fares: fill empty spaces with mean\n",
    "combined_features.head(891).Fare.fillna(combined_features.head(891).Fare.mean(), inplace=True)\n",
    "combined_features.iloc[891:].Fare.fillna(combined_features.iloc[891:].Fare.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Processing Embarked: drop it\n",
    "combined_features.drop('Embarked', axis=1, inplace=True)\n",
    "\n",
    "#Processing Ticket: drop it\n",
    "combined_features.drop('Ticket', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Processing Cabin:\n",
    "combined_features.Cabin.fillna('U', inplace=True)\n",
    "\n",
    "# mapping each Cabin value with the cabin letter\n",
    "combined_features['Cabin'] = combined_features['Cabin'].map(lambda c: c[0])\n",
    "\n",
    "cabin_dummies = pd.get_dummies(combined_features['Cabin'], prefix='Cabin')\n",
    "combined_features = pd.concat([combined_features, cabin_dummies], axis=1)\n",
    "combined_features.drop('Cabin', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing sex\n",
    "combined_features['Sex'] = combined_features['Sex'].map({'male':1,'female':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing pclass\n",
    "pclass_dummies = pd.get_dummies(combined_features['Pclass'], prefix=\"Pclass\")\n",
    "combined_features = pd.concat([combined_features, pclass_dummies], axis=1)\n",
    "combined_features.drop('Pclass', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing PassengerId\n",
    "combined_features.drop('PassengerId', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing family\n",
    "combined_features['FamilySize'] = combined_features['Parch'] + combined_features['SibSp'] + 1\n",
    "combined_features['Singleton'] = combined_features['FamilySize'].map(lambda s: 1 if s == 1 else 0)\n",
    "combined_features['SmallFamily'] = combined_features['FamilySize'].map(lambda s: 1 if 2 <= s <= 4 else 0)\n",
    "combined_features['LargeFamily'] = combined_features['FamilySize'].map(lambda s: 1 if 5 <= s else 0)\n",
    "combined_features.drop('Parch', axis=1, inplace=True)\n",
    "combined_features.drop('SibSp', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Sex       Age      Fare  Title_Master  Title_Miss  Title_Mr  Title_Mrs  \\\n",
      "0    1 -0.090295 -0.050841             0           0         1          0   \n",
      "1    0  0.109705  0.074144             0           0         0          1   \n",
      "2    0 -0.040295 -0.049523             0           1         0          0   \n",
      "3    0  0.072205  0.038652             0           0         0          1   \n",
      "4    1  0.072205 -0.049279             0           0         1          0   \n",
      "\n",
      "   Title_Officer  Title_Royalty  Cabin_A  ...  Cabin_G  Cabin_T  Cabin_U  \\\n",
      "0              0              0        0  ...        0        0        1   \n",
      "1              0              0        0  ...        0        0        0   \n",
      "2              0              0        0  ...        0        0        1   \n",
      "3              0              0        0  ...        0        0        0   \n",
      "4              0              0        0  ...        0        0        1   \n",
      "\n",
      "   Pclass_1  Pclass_2  Pclass_3  FamilySize  Singleton  SmallFamily  \\\n",
      "0         0         0         1           2          0            1   \n",
      "1         1         0         0           2          0            1   \n",
      "2         0         0         1           1          1            0   \n",
      "3         1         0         0           2          0            1   \n",
      "4         0         0         1           1          1            0   \n",
      "\n",
      "   LargeFamily  \n",
      "0            0  \n",
      "1            0  \n",
      "2            0  \n",
      "3            0  \n",
      "4            0  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "#Scaling\n",
    "scale=max(combined_features['Age'])\n",
    "combined_features['Age']/=scale\n",
    "mean=np.mean(combined_features['Age'])\n",
    "combined_features['Age']-=mean\n",
    "\n",
    "scale=max(combined_features['Fare'])\n",
    "combined_features['Fare']/=scale\n",
    "mean=np.mean(combined_features['Fare'])\n",
    "combined_features['Fare']-=mean\n",
    "\n",
    "\n",
    "print(combined_features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train=combined_features[:891]\n",
    "features_test=combined_features[891:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0707 23:44:19.985840 4501956032 deprecation_wrapper.py:119] From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0707 23:44:20.015707 4501956032 deprecation_wrapper.py:119] From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0707 23:44:20.025672 4501956032 deprecation_wrapper.py:119] From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0707 23:44:20.051149 4501956032 deprecation_wrapper.py:119] From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0707 23:44:20.065870 4501956032 deprecation.py:506] From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0707 23:44:20.156519 4501956032 deprecation_wrapper.py:119] From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0707 23:44:20.188033 4501956032 deprecation_wrapper.py:119] From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, input_dim=25))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "labels_train = np_utils.to_categorical(labels_train)\n",
    "\n",
    "# we'll use categorical xent for the loss, and RMSprop as the optimizer\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "clf=model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0707 23:44:55.658179 4501956032 deprecation.py:323] From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 801 samples, validate on 90 samples\n",
      "Epoch 1/88\n",
      "801/801 [==============================] - 1s 784us/step - loss: 0.5591 - acc: 0.7241 - val_loss: 0.4189 - val_acc: 0.8333\n",
      "Epoch 2/88\n",
      "801/801 [==============================] - 0s 123us/step - loss: 0.4569 - acc: 0.8127 - val_loss: 0.3838 - val_acc: 0.8444\n",
      "Epoch 3/88\n",
      "801/801 [==============================] - 0s 135us/step - loss: 0.4211 - acc: 0.8127 - val_loss: 0.3557 - val_acc: 0.8556\n",
      "Epoch 4/88\n",
      "801/801 [==============================] - 0s 187us/step - loss: 0.4127 - acc: 0.8302 - val_loss: 0.3385 - val_acc: 0.8556\n",
      "Epoch 5/88\n",
      "801/801 [==============================] - 0s 175us/step - loss: 0.4257 - acc: 0.8215 - val_loss: 0.3621 - val_acc: 0.8556\n",
      "Epoch 6/88\n",
      "801/801 [==============================] - 0s 141us/step - loss: 0.4127 - acc: 0.8315 - val_loss: 0.3435 - val_acc: 0.8444\n",
      "Epoch 7/88\n",
      "801/801 [==============================] - 0s 150us/step - loss: 0.4009 - acc: 0.8277 - val_loss: 0.3372 - val_acc: 0.8444\n",
      "Epoch 8/88\n",
      "801/801 [==============================] - 0s 150us/step - loss: 0.3920 - acc: 0.8390 - val_loss: 0.3337 - val_acc: 0.8444\n",
      "Epoch 9/88\n",
      "801/801 [==============================] - 0s 141us/step - loss: 0.3991 - acc: 0.8340 - val_loss: 0.3451 - val_acc: 0.8667\n",
      "Epoch 10/88\n",
      "801/801 [==============================] - 0s 120us/step - loss: 0.3917 - acc: 0.8277 - val_loss: 0.3362 - val_acc: 0.8222\n",
      "Epoch 11/88\n",
      "801/801 [==============================] - 0s 116us/step - loss: 0.3888 - acc: 0.8414 - val_loss: 0.3427 - val_acc: 0.8556\n",
      "Epoch 12/88\n",
      "801/801 [==============================] - 0s 163us/step - loss: 0.3938 - acc: 0.8340 - val_loss: 0.3453 - val_acc: 0.8667\n",
      "Epoch 13/88\n",
      "801/801 [==============================] - 0s 124us/step - loss: 0.3923 - acc: 0.8390 - val_loss: 0.3692 - val_acc: 0.8556\n",
      "Epoch 14/88\n",
      "801/801 [==============================] - 0s 121us/step - loss: 0.4001 - acc: 0.8340 - val_loss: 0.3217 - val_acc: 0.8444\n",
      "Epoch 15/88\n",
      "801/801 [==============================] - 0s 127us/step - loss: 0.3819 - acc: 0.8352 - val_loss: 0.3278 - val_acc: 0.8889\n",
      "Epoch 16/88\n",
      "801/801 [==============================] - 0s 168us/step - loss: 0.3874 - acc: 0.8202 - val_loss: 0.3437 - val_acc: 0.8889\n",
      "Epoch 17/88\n",
      "801/801 [==============================] - 0s 168us/step - loss: 0.4127 - acc: 0.8077 - val_loss: 0.3382 - val_acc: 0.8556\n",
      "Epoch 18/88\n",
      "801/801 [==============================] - 0s 144us/step - loss: 0.3845 - acc: 0.8402 - val_loss: 0.3180 - val_acc: 0.8444\n",
      "Epoch 19/88\n",
      "801/801 [==============================] - 0s 132us/step - loss: 0.3925 - acc: 0.8452 - val_loss: 0.3151 - val_acc: 0.8444\n",
      "Epoch 20/88\n",
      "801/801 [==============================] - 0s 135us/step - loss: 0.3880 - acc: 0.8377 - val_loss: 0.3136 - val_acc: 0.8667\n",
      "Epoch 21/88\n",
      "801/801 [==============================] - 0s 138us/step - loss: 0.3727 - acc: 0.8477 - val_loss: 0.3079 - val_acc: 0.8556\n",
      "Epoch 22/88\n",
      "801/801 [==============================] - 0s 122us/step - loss: 0.3855 - acc: 0.8402 - val_loss: 0.3202 - val_acc: 0.8667\n",
      "Epoch 23/88\n",
      "801/801 [==============================] - 0s 115us/step - loss: 0.3750 - acc: 0.8489 - val_loss: 0.3119 - val_acc: 0.8556\n",
      "Epoch 24/88\n",
      "801/801 [==============================] - 0s 124us/step - loss: 0.3869 - acc: 0.8464 - val_loss: 0.3058 - val_acc: 0.8444\n",
      "Epoch 25/88\n",
      "801/801 [==============================] - 0s 124us/step - loss: 0.3786 - acc: 0.8414 - val_loss: 0.3422 - val_acc: 0.8667\n",
      "Epoch 26/88\n",
      "801/801 [==============================] - 0s 123us/step - loss: 0.4047 - acc: 0.8414 - val_loss: 0.3236 - val_acc: 0.8556\n",
      "Epoch 27/88\n",
      "801/801 [==============================] - 0s 179us/step - loss: 0.4053 - acc: 0.8215 - val_loss: 0.3130 - val_acc: 0.8556\n",
      "Epoch 28/88\n",
      "801/801 [==============================] - 0s 168us/step - loss: 0.3977 - acc: 0.8365 - val_loss: 0.3240 - val_acc: 0.8222\n",
      "Epoch 29/88\n",
      "801/801 [==============================] - 0s 163us/step - loss: 0.3722 - acc: 0.8464 - val_loss: 0.3188 - val_acc: 0.8444\n",
      "Epoch 30/88\n",
      "801/801 [==============================] - 0s 155us/step - loss: 0.3771 - acc: 0.8452 - val_loss: 0.3227 - val_acc: 0.8556\n",
      "Epoch 31/88\n",
      "801/801 [==============================] - 0s 158us/step - loss: 0.3770 - acc: 0.8464 - val_loss: 0.3137 - val_acc: 0.8556\n",
      "Epoch 32/88\n",
      "801/801 [==============================] - 0s 162us/step - loss: 0.3734 - acc: 0.8502 - val_loss: 0.2990 - val_acc: 0.8667\n",
      "Epoch 33/88\n",
      "801/801 [==============================] - 0s 135us/step - loss: 0.3616 - acc: 0.8527 - val_loss: 0.3081 - val_acc: 0.8667\n",
      "Epoch 34/88\n",
      "801/801 [==============================] - 0s 131us/step - loss: 0.3616 - acc: 0.8539 - val_loss: 0.3100 - val_acc: 0.8556\n",
      "Epoch 35/88\n",
      "801/801 [==============================] - 0s 135us/step - loss: 0.3611 - acc: 0.8564 - val_loss: 0.3158 - val_acc: 0.8556\n",
      "Epoch 36/88\n",
      "801/801 [==============================] - 0s 125us/step - loss: 0.3578 - acc: 0.8489 - val_loss: 0.3057 - val_acc: 0.8556\n",
      "Epoch 37/88\n",
      "801/801 [==============================] - 0s 122us/step - loss: 0.3698 - acc: 0.8527 - val_loss: 0.3172 - val_acc: 0.8556\n",
      "Epoch 38/88\n",
      "801/801 [==============================] - 0s 129us/step - loss: 0.3776 - acc: 0.8402 - val_loss: 0.3069 - val_acc: 0.8444\n",
      "Epoch 39/88\n",
      "801/801 [==============================] - 0s 161us/step - loss: 0.3692 - acc: 0.8390 - val_loss: 0.3324 - val_acc: 0.8556\n",
      "Epoch 40/88\n",
      "801/801 [==============================] - 0s 167us/step - loss: 0.3701 - acc: 0.8539 - val_loss: 0.3090 - val_acc: 0.8222\n",
      "Epoch 41/88\n",
      "801/801 [==============================] - 0s 120us/step - loss: 0.3597 - acc: 0.8414 - val_loss: 0.3023 - val_acc: 0.8333\n",
      "Epoch 42/88\n",
      "801/801 [==============================] - 0s 131us/step - loss: 0.3564 - acc: 0.8464 - val_loss: 0.3086 - val_acc: 0.8444\n",
      "Epoch 43/88\n",
      "801/801 [==============================] - 0s 128us/step - loss: 0.3531 - acc: 0.8564 - val_loss: 0.3069 - val_acc: 0.8333\n",
      "Epoch 44/88\n",
      "801/801 [==============================] - 0s 127us/step - loss: 0.3458 - acc: 0.8527 - val_loss: 0.3248 - val_acc: 0.8556\n",
      "Epoch 45/88\n",
      "801/801 [==============================] - 0s 133us/step - loss: 0.3592 - acc: 0.8564 - val_loss: 0.3068 - val_acc: 0.8444\n",
      "Epoch 46/88\n",
      "801/801 [==============================] - 0s 124us/step - loss: 0.3443 - acc: 0.8589 - val_loss: 0.3161 - val_acc: 0.8667\n",
      "Epoch 47/88\n",
      "801/801 [==============================] - 0s 119us/step - loss: 0.3413 - acc: 0.8614 - val_loss: 0.3073 - val_acc: 0.8444\n",
      "Epoch 48/88\n",
      "801/801 [==============================] - 0s 133us/step - loss: 0.3496 - acc: 0.8577 - val_loss: 0.3077 - val_acc: 0.8444\n",
      "Epoch 49/88\n",
      "801/801 [==============================] - 0s 121us/step - loss: 0.3526 - acc: 0.8489 - val_loss: 0.3221 - val_acc: 0.8556\n",
      "Epoch 50/88\n",
      "801/801 [==============================] - 0s 138us/step - loss: 0.3510 - acc: 0.8477 - val_loss: 0.3145 - val_acc: 0.8444\n",
      "Epoch 51/88\n",
      "801/801 [==============================] - 0s 136us/step - loss: 0.3625 - acc: 0.8602 - val_loss: 0.3231 - val_acc: 0.8556\n",
      "Epoch 52/88\n",
      "801/801 [==============================] - 0s 125us/step - loss: 0.3506 - acc: 0.8539 - val_loss: 0.3094 - val_acc: 0.8333\n",
      "Epoch 53/88\n",
      "801/801 [==============================] - 0s 126us/step - loss: 0.3525 - acc: 0.8564 - val_loss: 0.3206 - val_acc: 0.8444\n",
      "Epoch 54/88\n",
      "801/801 [==============================] - 0s 127us/step - loss: 0.3515 - acc: 0.8552 - val_loss: 0.2972 - val_acc: 0.8333\n",
      "Epoch 55/88\n",
      "801/801 [==============================] - 0s 113us/step - loss: 0.3471 - acc: 0.8527 - val_loss: 0.3165 - val_acc: 0.8556\n",
      "Epoch 56/88\n",
      "801/801 [==============================] - 0s 128us/step - loss: 0.3468 - acc: 0.8589 - val_loss: 0.2981 - val_acc: 0.8556\n",
      "Epoch 57/88\n",
      "801/801 [==============================] - 0s 122us/step - loss: 0.3407 - acc: 0.8589 - val_loss: 0.3263 - val_acc: 0.8556\n",
      "Epoch 58/88\n",
      "801/801 [==============================] - 0s 130us/step - loss: 0.3435 - acc: 0.8577 - val_loss: 0.3144 - val_acc: 0.8556\n",
      "Epoch 59/88\n",
      "801/801 [==============================] - 0s 138us/step - loss: 0.3513 - acc: 0.8527 - val_loss: 0.3211 - val_acc: 0.8333\n",
      "Epoch 60/88\n",
      "801/801 [==============================] - 0s 124us/step - loss: 0.3662 - acc: 0.8589 - val_loss: 0.3282 - val_acc: 0.8333\n",
      "Epoch 61/88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "801/801 [==============================] - 0s 122us/step - loss: 0.3455 - acc: 0.8577 - val_loss: 0.3255 - val_acc: 0.8556\n",
      "Epoch 62/88\n",
      "801/801 [==============================] - 0s 116us/step - loss: 0.3640 - acc: 0.8427 - val_loss: 0.3196 - val_acc: 0.8333\n",
      "Epoch 63/88\n",
      "801/801 [==============================] - 0s 114us/step - loss: 0.3342 - acc: 0.8689 - val_loss: 0.3357 - val_acc: 0.8333\n",
      "Epoch 64/88\n",
      "801/801 [==============================] - 0s 112us/step - loss: 0.3470 - acc: 0.8602 - val_loss: 0.3090 - val_acc: 0.8333\n",
      "Epoch 65/88\n",
      "801/801 [==============================] - 0s 113us/step - loss: 0.3387 - acc: 0.8502 - val_loss: 0.3178 - val_acc: 0.8333\n",
      "Epoch 66/88\n",
      "801/801 [==============================] - 0s 116us/step - loss: 0.3437 - acc: 0.8627 - val_loss: 0.3480 - val_acc: 0.8444\n",
      "Epoch 67/88\n",
      "801/801 [==============================] - 0s 115us/step - loss: 0.3392 - acc: 0.8639 - val_loss: 0.3081 - val_acc: 0.8667\n",
      "Epoch 68/88\n",
      "801/801 [==============================] - 0s 114us/step - loss: 0.3457 - acc: 0.8514 - val_loss: 0.3100 - val_acc: 0.8444\n",
      "Epoch 69/88\n",
      "801/801 [==============================] - 0s 116us/step - loss: 0.3351 - acc: 0.8652 - val_loss: 0.3181 - val_acc: 0.8556\n",
      "Epoch 70/88\n",
      "801/801 [==============================] - 0s 132us/step - loss: 0.3518 - acc: 0.8527 - val_loss: 0.3249 - val_acc: 0.8667\n",
      "Epoch 71/88\n",
      "801/801 [==============================] - 0s 139us/step - loss: 0.3418 - acc: 0.8602 - val_loss: 0.3092 - val_acc: 0.8556\n",
      "Epoch 72/88\n",
      "801/801 [==============================] - 0s 121us/step - loss: 0.3418 - acc: 0.8527 - val_loss: 0.3043 - val_acc: 0.8444\n",
      "Epoch 73/88\n",
      "801/801 [==============================] - 0s 114us/step - loss: 0.3414 - acc: 0.8614 - val_loss: 0.3388 - val_acc: 0.8556\n",
      "Epoch 74/88\n",
      "801/801 [==============================] - 0s 119us/step - loss: 0.3303 - acc: 0.8627 - val_loss: 0.3228 - val_acc: 0.8333\n",
      "Epoch 75/88\n",
      "801/801 [==============================] - 0s 167us/step - loss: 0.3352 - acc: 0.8627 - val_loss: 0.3144 - val_acc: 0.8556\n",
      "Epoch 76/88\n",
      "801/801 [==============================] - 0s 155us/step - loss: 0.3372 - acc: 0.8577 - val_loss: 0.3175 - val_acc: 0.8444\n",
      "Epoch 77/88\n",
      "801/801 [==============================] - 0s 155us/step - loss: 0.3355 - acc: 0.8627 - val_loss: 0.3400 - val_acc: 0.8667\n",
      "Epoch 78/88\n",
      "801/801 [==============================] - 0s 141us/step - loss: 0.3330 - acc: 0.8639 - val_loss: 0.3114 - val_acc: 0.8556\n",
      "Epoch 79/88\n",
      "801/801 [==============================] - 0s 137us/step - loss: 0.3322 - acc: 0.8689 - val_loss: 0.3237 - val_acc: 0.8333\n",
      "Epoch 80/88\n",
      "801/801 [==============================] - 0s 135us/step - loss: 0.3375 - acc: 0.8627 - val_loss: 0.3242 - val_acc: 0.8556\n",
      "Epoch 81/88\n",
      "801/801 [==============================] - 0s 130us/step - loss: 0.3401 - acc: 0.8689 - val_loss: 0.3140 - val_acc: 0.8556\n",
      "Epoch 82/88\n",
      "801/801 [==============================] - 0s 180us/step - loss: 0.3295 - acc: 0.8664 - val_loss: 0.3152 - val_acc: 0.8778\n",
      "Epoch 83/88\n",
      "801/801 [==============================] - 0s 180us/step - loss: 0.3346 - acc: 0.8627 - val_loss: 0.3277 - val_acc: 0.8667\n",
      "Epoch 84/88\n",
      "801/801 [==============================] - 0s 171us/step - loss: 0.3285 - acc: 0.8602 - val_loss: 0.3244 - val_acc: 0.8667\n",
      "Epoch 85/88\n",
      "801/801 [==============================] - 0s 174us/step - loss: 0.3326 - acc: 0.8589 - val_loss: 0.3275 - val_acc: 0.8556\n",
      "Epoch 86/88\n",
      "801/801 [==============================] - 0s 193us/step - loss: 0.3314 - acc: 0.8564 - val_loss: 0.3203 - val_acc: 0.8667\n",
      "Epoch 87/88\n",
      "801/801 [==============================] - 0s 159us/step - loss: 0.3283 - acc: 0.8614 - val_loss: 0.3160 - val_acc: 0.8667\n",
      "Epoch 88/88\n",
      "801/801 [==============================] - 0s 150us/step - loss: 0.3314 - acc: 0.8689 - val_loss: 0.3076 - val_acc: 0.8444\n"
     ]
    }
   ],
   "source": [
    "clf.fit(np.array(features_train),labels_train,validation_split=0.1,epochs=88)\n",
    "out = clf.predict(np.array(features_test))\n",
    "#print(accuracy_score(out,labels_test))\n",
    "pred=[]\n",
    "for x in out:\n",
    "    if(x[1]>0.5):\n",
    "        pred.append(1)\n",
    "    else:\n",
    "        pred.append(0)\n",
    "\n",
    "out1=pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "idk = open('test.csv','r')\n",
    "idk = csv.DictReader(idk)\n",
    "pred = []\n",
    "for row in idk:\n",
    "    pred.append(row[\"PassengerId\"])\n",
    "est = csv.writer(open('result.csv', 'w'), delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "est.writerows([[\"PassengerID\",\"Survived\"]])\n",
    "k=0\n",
    "for x in pred:\n",
    "    est.writerows([[str(x), str(out1[k])]])\n",
    "    k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
